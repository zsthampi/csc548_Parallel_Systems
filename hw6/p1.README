// zsthampi -  Zubin S Thampi

Describe your implementation step-by-step. This should include descriptions of what MPI messages get sent/received by which rank, and in what order.
===========================================================================================================
1. The first thing I did is to create a custom datatype for the 2 structures used in the algorithm. I used MPI_Type_create_struct method. I added additional comments in the code. 
2. If the rank is 0, get the list of files (rather the number of files in this case)
3. All ranks except 0, distribute the files among themselves.

Ex : If there are total 4 ranks, 
rank 1 works on files 1,4,7 ...
rank 2 works on files 2,5,8 ...
rank 3 works on files 3,6,9 ...

4. Each rank communicates the TFIDF structure values to rank 0. Rank 0 collects, and combines them 
5. Each rank communicates the Unique Words structure values to rank 0. Rank 0 collects, and combines them. This step requires some additional logic, since some of the values may be common across different processes. 
6. Once rank 0 has all the required data, it computes the TFIDF values. This step is ditto similar to the serial code.


Describe how you could add more parallelism to your code so that all of the processors on each MPI node are used instead of only one processor per MPI node.
===========================================================================================================
Each process iterates through the files in a for loop. 
I can parallellize the for loop using OpenMP, to utilize the processors per MPI node.

Implement the additional parallelism you just described. Submit this as TFIDF_extra.c. Compare this implementation to your MPI implementation.
===========================================================================================================


Compare your MPI implementation to the previous MapReduce and Spark implementations of TFIDF.
===========================================================================================================
